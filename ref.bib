@STRING{AAAI15 = {Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence}}
@STRING{CVPR = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}}
@STRING{ICCV = {Proceedings of the IEEE International Conference on Computer Vision}}
@STRING{BMVC = {Proceedings of the British Machine Vision Conference}}
@STRING{NIPS = {Advances in Neural Information Processing Systems}}
@STRING{ECCV = {The European Conference on Computer Vision (ECCV)}}
@STRING{ACCV = {Proceedings of the Asian Conference on Computer Vision}}
@STRING{CVPRW = {Proceedings of the Computer Vision and Pattern Recognition Workshops}}
@STRING{ICML = {Proceedings of the International Conference on Machine Learning}}
@STRING{ICPR = {Proceedings of the International Conference on Pattern Recognition}}
@STRING{IROS = {proceedings of IEEE/RSJ International Conference on Intelligent Robots and Systems}}
@STRING{ICRA = {proceedings of IEEE International Conference on Robotics and Automation}}
@STRING{IJRR = {The International Journal of Robotics Research}}
@STRING{IJCV = {International Journal of Computer Vision}}


@article{yin2022bioslam,
  title={BioSLAM: A Bio-inspired Lifelong Memory System for General Place Recognition},
  author={Yin, Peng and Abuduweili, Abulikemu and Zhao, Shiqi and Liu, Changliu and Scherer, Sebastian},
  journal={IEEE Transactions on Robotics, Conditional Accepted},
  url={https://arxiv.org/abs/2208.14543},
  video={https://youtu.be/PPOmyz2UVIw},
  year={2022},
}

@INPROCEEDINGS{pinto2017asymmetric,
  AUTHOR    = {Lerrel Pinto AND Marcin Andrychowicz AND Peter Welinder AND Wojciech Zaremba AND Pieter Abbeel},
  TITLE     = {Asymmetric Actor Critic for Image-Based Robot Learning},
  BOOKTITLE = {Proceedings of Robotics: Science and Systems},
  YEAR      = {2018},
  ADDRESS   = {Pittsburgh, Pennsylvania},
  MONTH     = {June},
  DOI       = {10.15607/RSS.2018.XIV.008}
}

@inproceedings{huang2017arbitrary,
  title={Arbitrary style transfer in real-time with adaptive instance normalization},
  author={Huang, Xun and Belongie, Serge},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={1501--1510},
  year={2017}
}

@inproceedings{krizhevsky2012imagenet,
	title = {ImageNet Classification with Deep Convolutional Neural Networks},
	author = {Alex Krizhevsky and Sutskever, Ilya and Hinton, Geoffrey E},
	booktitle = {Advances in Neural Information Processing Systems 25},
	editor = {F. Pereira and C. J. C. Burges and L. Bottou and K. Q. Weinberger},
	pages = {1097--1105},
	year = {2012},
	publisher = {Curran Associates, Inc.},
	url = {http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf}
}
@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={770--778},
  year={2016}
}
@inproceedings{huang2017densely,
  title={Densely connected convolutional networks},
  author={Huang, Gao and Liu, Zhuang and Weinberger, Kilian Q and van der Maaten, Laurens},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={4700--4708},
  year={2017}
}
@inproceedings{gu2016continuous,
  title={Continuous Deep Q-Learning with Model-based Acceleration},
  author={Gu, Shixiang and Lillicrap, Timothy and Sutskever, Ilya and Levine, Sergey},
  booktitle={Proceedings of The 33rd International Conference on Machine Learning},
  pages={2829--2838},
  year={2016}
}
@InProceedings{wang2015dueling,
  title = 	 {Dueling Network Architectures for Deep Reinforcement Learning},
  author = 	 {Ziyu Wang and Tom Schaul and Matteo Hessel and Hado Hasselt and Marc Lanctot and Nando Freitas},
  booktitle = 	 {Proceedings of The 33rd International Conference on Machine Learning},
  pages = 	 {1995--2003},
  year = 	 {2016},
  editor = 	 {Maria Florina Balcan and Kilian Q. Weinberger},
  volume = 	 {48},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {New York, New York, USA},
  month = 	 {20--22 Jun},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v48/wangf16.pdf},
  url = 	 {http://proceedings.mlr.press/v48/wangf16.html},
  abstract = 	 {In recent years there have been many successes of using deep representations in reinforcement learning. Still, many of these applications use conventional architectures, such as convolutional networks, LSTMs, or auto-encoders. In this paper, we present a new neural network architecture for model-free reinforcement learning. Our dueling network represents two separate estimators: one for the state value function and one for the state-dependent action advantage function. The main benefit of this factoring is to generalize learning across actions without imposing any change to the underlying reinforcement learning algorithm. Our results show that this architecture leads to better policy evaluation in the presence of many similar-valued actions. Moreover, the dueling architecture enables our RL agent to outperform the state-of-the-art on the Atari 2600 domain.}
}
@article{hausknecht2015deep,
  title={Deep recurrent q-learning for partially observable mdps},
  author={Hausknecht, Matthew and Stone, Peter},
  journal={arXiv preprint arXiv:1507.06527},
  year={2015}
}
@inproceedings{gu2016deep,
  title={Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates},
  author={Gu, Shixiang and Holly, Ethan and Lillicrap, Timothy and Levine, Sergey},
  booktitle={2017 IEEE international conference on robotics and automation (ICRA)},
  pages={3389--3396},
  year={2017},
  organization={IEEE}
}
@inproceedings{long2015fully,
  title={Fully convolutional networks for semantic segmentation},
  author={Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={3431--3440},
  year={2015}
}
@article{chen2016deeplab,
  title={Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs},
  author={Chen, Liang-Chieh and Papandreou, George and Kokkinos, Iasonas and Murphy, Kevin and Yuille, Alan L},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2018},
  volume={40},
  number={4},
  pages={834-848},
  keywords={convolution;feature extraction;feedforward neural nets;image segmentation;learning (artificial intelligence);random processes;highlight convolution;atrous convolution;Deep Convolutional Neural Networks;atrous spatial pyramid pooling;image context;fully connected Conditional Random Field;PASCAL VOC-2012 semantic image segmentation task;deep convolutional nets;Deep Learning;DeepLab;semantic image segmentation;probabilistic graphical models;Convolution;Image segmentation;Semantics;Image resolution;Computational modeling;Neural networks;Context;Convolutional neural networks;semantic segmentation;atrous convolution;conditional random fields},
  doi={10.1109/TPAMI.2017.2699184},
  ISSN={0162-8828},
  month={April}
}

@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}
@inproceedings{rohmer2013v,
  title={V-REP: A versatile and scalable robot simulation framework},
  author={Rohmer, Eric and Singh, Surya PN and Freese, Marc},
  booktitle={2013 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={1321--1326},
  year={2013},
  organization={IEEE}
}

@InProceedings{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  booktitle={International Conference on Learning Representations},
  year={2015}
}
@incollection{rasmussen2006gaussian,
  title={Gaussian processes in machine learning},
  author={Rasmussen, Carl Edward},
  booktitle={Advanced lectures on machine learning},
  pages={63--71},
  year={2004},
  publisher={Springer}
}
@inproceedings{pfeiffer2016predicting,
  title={Predicting actions to act predictably: Cooperative partial motion planning with maximum entropy models},
  author={Pfeiffer, Mark and Schwesinger, Ulrich and Sommer, Hannes and Galceran, Enric and Siegwart, Roland},
  booktitle={2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={2096--2101},
  year={2016},
  organization={IEEE}
}

@inproceedings{arora2017generalization,
  title={Generalization and equilibrium in generative adversarial nets (gans)},
  author={Arora, Sanjeev and Ge, Rong and Liang, Yingyu and Ma, Tengyu and Zhang, Yi},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={224--232},
  year={2017},
  organization={JMLR. org}
}

@article{kretzschmar2016socially,
  title={Socially compliant mobile robot navigation via inverse reinforcement learning},
  author={Kretzschmar, Henrik and Spies, Markus and Sprunk, Christoph and Burgard, Wolfram},
  journal={The International Journal of Robotics Research},
  volume={35},
  number={11},
  pages={1289--1307},
  year={2016},
  publisher={SAGE Publications Sage UK: London, England}
}
@inproceedings{ho2016generative,
  title = {Generative Adversarial Imitation Learning},
  author = {Ho, Jonathan and Ermon, Stefano},
  booktitle = {Advances in Neural Information Processing Systems 29},
  editor = {D. D. Lee and M. Sugiyama and U. V. Luxburg and I. Guyon and R. Garnett},
  pages = {4565--4573},
  year = {2016},
  publisher = {Curran Associates, Inc.},
  url = {http://papers.nips.cc/paper/6391-generative-adversarial-imitation-learning.pdf}
}

@inproceedings{schulman2015trust,
  title = 	 {Trust Region Policy Optimization},
  author = 	 {John Schulman and Sergey Levine and Pieter Abbeel and Michael Jordan and Philipp Moritz},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {1889--1897},
  year = 	 {2015},
  editor = 	 {Francis Bach and David Blei},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lille, France},
  month = 	 {07--09 Jul},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v37/schulman15.pdf},
  url = 	 {http://proceedings.mlr.press/v37/schulman15.html},
  abstract = 	 {In this article, we describe a method for optimizing control policies, with guaranteed monotonic improvement. By making several approximations to the theoretically-justified scheme, we develop a practical algorithm, called Trust Region Policy Optimization (TRPO). This algorithm is effective for optimizing large nonlinear policies such as neural networks. Our experiments demonstrate its robust performance on a wide variety of tasks: learning simulated robotic swimming, hopping, and walking gaits; and playing Atari games using images of the screen as input. Despite its approximations that deviate from the theory, TRPO tends to give monotonic improvement, with little tuning of hyperparameters.}
}

@InProceedings{arjovsky2017wasserstein,
  title = 	 {{W}asserstein Generative Adversarial Networks},
  author = 	 {Martin Arjovsky and Soumith Chintala and L{\'e}on Bottou},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {214--223},
  year = 	 {2017},
  editor = 	 {Doina Precup and Yee Whye Teh},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {International Convention Centre, Sydney, Australia},
  month = 	 {06--11 Aug},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v70/arjovsky17a/arjovsky17a.pdf},
  url = 	 {http://proceedings.mlr.press/v70/arjovsky17a.html},
  abstract = 	 {We introduce a new algorithm named WGAN, an alternative to traditional GAN training. In this new model, we show that we can improve the stability of learning, get rid of problems like mode collapse, and provide meaningful learning curves useful for debugging and hyperparameter searches. Furthermore, we show that the corresponding optimization problem is sound, and provide extensive theoretical work highlighting the deep connections to different distances between distributions.}
}

@InProceedings{li2017inferring,
  title = {InfoGAIL: Interpretable Imitation Learning from Visual Demonstrations},
  author = {Li, Yunzhu and Song, Jiaming and Ermon, Stefano},
  booktitle = {Advances in Neural Information Processing Systems 30},
  editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
  pages = {3812--3822},
  year = {2017},
  publisher = {Curran Associates, Inc.},
  url = {http://papers.nips.cc/paper/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations.pdf}
}

@article{helbing1995social,
  title={Social force model for pedestrian dynamics},
  author={Helbing, Dirk and Molnar, Peter},
  journal={Physical review E},
  volume={51},
  number={5},
  pages={4282},
  year={1995},
  publisher={APS}
}
@inproceedings{van2008reciprocal,
  title={Reciprocal velocity obstacles for real-time multi-agent navigation},
  author={Van den Berg, Jur and Lin, Ming and Manocha, Dinesh},
  booktitle={2008 IEEE international conference on robotics and automation (ICRA)},
  pages={1928--1935},
  year={2008},
  month={May}
}
@book{Goodfellow-et-al-2016,
  title={Deep Learning},
  author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
  publisher={MIT Press},
  volume={1},
  year={2016}
}
@inproceedings{zhu2017target,
  title={Target-driven visual navigation in indoor scenes using deep reinforcement learning},
  author={Zhu, Yuke and Mottaghi, Roozbeh and Kolve, Eric and Lim, Joseph J and Gupta, Abhinav and Fei-Fei, Li and Farhadi, Ali},
  booktitle={2017 IEEE international conference on robotics and automation (ICRA)},
  pages={3357--3364},
  year={2017},
  organization={IEEE}
}
@article{zhang2015towards,
  title={Towards vision-based deep reinforcement learning for robotic motion control},
  author={Zhang, Fangyi and Leitner, J{\"u}rgen and Milford, Michael and Upcroft, Ben and Corke, Peter},
  journal={arXiv preprint arXiv:1511.03791},
  year={2015}
}
@article{srivastava2014dropout,
  title={Dropout: a simple way to prevent neural networks from overfitting.},
  author={Srivastava, Nitish and Hinton, Geoffrey E and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  journal={Journal of Machine Learning Research},
  volume={15},
  number={1},
  pages={1929--1958},
  year={2014}
}
@inproceedings{jia2014caffe,
  title={Caffe: Convolutional architecture for fast feature embedding},
  author={Jia, Yangqing and Shelhamer, Evan and Donahue, Jeff and Karayev, Sergey and Long, Jonathan and Girshick, Ross and Guadarrama, Sergio and Darrell, Trevor},
  booktitle={Proceedings of the 22nd ACM international conference on Multimedia},
  pages={675--678},
  year={2014},
  organization={ACM}
}
@inproceedings{zhang2017deep,
  author={Zhang, Jingwei and Springenberg, Jost Tobias and Boedecker, Joschka and Burgard, Wolfram},
  booktitle={2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title={Deep reinforcement learning with successor features for navigation across similar environments},
  year={2017},
  pages={2371-2378},
  month={Sept},
}
@inproceedings{zeiler2014visualizing,
  title={Visualizing and understanding convolutional networks},
  author={Zeiler, Matthew D and Fergus, Rob},
  booktitle={The European Conference on Computer Vision (ECCV)},
  pages={818--833},
  year={2014},
  organization={Springer}
}

@article{levine2016end,
  title={End-to-end training of deep visuomotor policies},
  author={Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={1334--1373},
  year={2016},
  publisher={JMLR. org}
}
@INPROCEEDINGS{yu2018one,
  AUTHOR    = {Tianhe Yu AND Chelsea Finn AND Sudeep Dasari AND Annie Xie AND Tianhao Zhang AND Pieter Abbeel AND Sergey Levine},
  TITLE     = {One-Shot Imitation from Observing Humans via Domain-Adaptive Meta-Learning},
  BOOKTITLE = {Proceedings of Robotics: Science and Systems},
  YEAR      = {2018},
  ADDRESS   = {Pittsburgh, Pennsylvania},
  MONTH     = {June},
  DOI       = {10.15607/RSS.2018.XIV.002}
}

@article{schmidhuber2015deep,
  title={Deep learning in neural networks: An overview},
  author={Schmidhuber, J{\"u}rgen},
  journal={Neural networks},
  volume={61},
  pages={85--117},
  year={2015},
  publisher={Elsevier}
}
@article{deng2014tutorial,
  title={A tutorial survey of architectures, algorithms, and applications for deep learning},
  author={Deng, Li},
  journal={APSIPA Transactions on Signal and Information Processing},
  volume={3},
  year={2014},
  publisher={Cambridge University Press}
}
@article{guo2016deep,
  title={Deep learning for visual understanding: A review},
  author={Guo, Yanming and Liu, Yu and Oerlemans, Ard and Lao, Songyang and Wu, Song and Lew, Michael S},
  journal={Neurocomputing},
  volume={187},
  pages={27--48},
  year={2016},
  publisher={Elsevier}
}
@techreport{bagnell2015invitation,
  title={An invitation to imitation},
  author={Bagnell, J Andrew},
  year={2015},
  institution={CARNEGIE-MELLON UNIV PITTSBURGH PA ROBOTICS INST}
}
@article{heess2017emergence,
  title={Emergence of locomotion behaviours in rich environments},
  author={Heess, Nicolas and Sriram, Srinivasan and Lemmon, Jay and Merel, Josh and Wayne, Greg and Tassa, Yuval and Erez, Tom and Wang, Ziyu and Eslami, Ali and Riedmiller, Martin and others},
  journal={arXiv preprint arXiv:1707.02286},
  year={2017}
}
@inproceedings{wu2017scalable,
	title = {Scalable trust-region method for deep reinforcement learning using Kronecker-factored approximation},
	author = {Wu, Yuhuai and Mansimov, Elman and Grosse, Roger B and Liao, Shun and Ba, Jimmy},
	booktitle = {Advances in Neural Information Processing Systems 30},
	editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
	pages = {5279--5288},
	year = {2017},
	publisher = {Curran Associates, Inc.},
	url = {http://papers.nips.cc/paper/7112-scalable-trust-region-method-for-deep-reinforcement-learning-using-kronecker-factored-approximation.pdf}
}
@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}
@inproceedings{finn2016deep,
  title={Deep spatial autoencoders for visuomotor learning},
  author={Finn, Chelsea and Tan, Xin Yu and Duan, Yan and Darrell, Trevor and Levine, Sergey and Abbeel, Pieter},
  booktitle={2016 IEEE international conference on robotics and automation (ICRA)},
  pages={512--519},
  year={2016},
  organization={IEEE}
}
@article{tzeng2015towards,
  title={Towards Adapting Deep Visuomotor Representations from Simulated to Real Environments},
  author={Tzeng, Eric and Devin, Coline and Hoffman, Judy and Finn, Chelsea and Abbeel, Pieter and Levine, Sergey and Saenko, Kate and Darrell, Trevor},
  journal={arXiv preprint arXiv:1511.07111},
  year={2015}
}

@inproceedings{fu2016one,
  title={One-shot learning of manipulation skills with online dynamics adaptation and neural network priors},
  author={Fu, Justin and Levine, Sergey and Abbeel, Pieter},
  booktitle={2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={4019--4026},
  year={2016},
  organization={IEEE}
}
@inproceedings{kumar2016optimal,
  title={Optimal control with learned local models: Application to dexterous manipulation},
  author={Kumar, Vikash and Todorov, Emanuel and Levine, Sergey},
  booktitle={2016 IEEE international conference on robotics and automation (ICRA)},
  pages={378--383},
  year={2016},
  organization={IEEE}
}

@inproceedings{gupta2016learning,
  title={Learning dexterous manipulation for a soft robotic hand from human demonstrations},
  author={Gupta, Abhishek and Eppner, Clemens and Levine, Sergey and Abbeel, Pieter},
  booktitle={2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={3786--3793},
  year={2016},
  organization={IEEE}
}

@article{popov2017data,
  title={Data-efficient deep reinforcement learning for dexterous manipulation},
  author={Popov, Ivaylo and Heess, Nicolas and Lillicrap, Timothy and Hafner, Roland and Barth-Maron, Gabriel and Vecerik, Matej and Lampe, Thomas and Tassa, Yuval and Erez, Tom and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1704.03073},
  year={2017}
}
@InProceedings{martin2018learning,
  title = 	 {Learning by Playing Solving Sparse Reward Tasks from Scratch},
  author = 	 {Riedmiller, Martin and Hafner, Roland and Lampe, Thomas and Neunert, Michael and Degrave, Jonas and van de Wiele, Tom and Mnih, Vlad and Heess, Nicolas and Springenberg, Jost Tobias},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {4344--4353},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Stockholmsmässan, Stockholm Sweden},
  month = 	 {10--15 Jul},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/riedmiller18a/riedmiller18a.pdf},
  url = 	 {http://proceedings.mlr.press/v80/riedmiller18a.html},
  abstract = 	 {We propose Scheduled Auxiliary Control (SAC-X), a new learning paradigm in the context of Reinforcement Learning (RL). SAC-X enables learning of complex behaviors - from scratch - in the presence of multiple sparse reward signals. To this end, the agent is equipped with a set of general auxiliary tasks, that it attempts to learn simultaneously via off-policy RL. The key idea behind our method is that active (learned) scheduling and execution of auxiliary policies allows the agent to efficiently explore its environment - enabling it to excel at sparse reward RL. Our experiments in several challenging robotic manipulation settings demonstrate the power of our approach.}
}

@article{kulkarni2016deep,
  title={Deep successor reinforcement learning},
  author={Kulkarni, Tejas D and Saeedi, Ardavan and Gautam, Simanta and Gershman, Samuel J},
  journal={arXiv preprint arXiv:1606.02396},
  year={2016}
}

@inproceedings{barreto2017successor,
  title={Successor features for transfer in reinforcement learning},
  author={Barreto, Andr{\'e} and Dabney, Will and Munos, R{\'e}mi and Hunt, Jonathan J and Schaul, Tom and Silver, David and van Hasselt, Hado P},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4058--4068},
  year={2017}
}

@inproceedings{schaul2015universal,
  title = 	 {Universal Value Function Approximators},
  author = 	 {Tom Schaul and Daniel Horgan and Karol Gregor and David Silver},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {1312--1320},
  year = 	 {2015},
  editor = 	 {Francis Bach and David Blei},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lille, France},
  month = 	 {07--09 Jul},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v37/schaul15.pdf},
  url = 	 {http://proceedings.mlr.press/v37/schaul15.html},
  abstract = 	 {Value functions are a core component of reinforcement learning. The main idea is to to construct a single function approximator V(s; theta) that estimates the long-term reward from any state s, using parameters θ. In this paper we introduce universal value function approximators (UVFAs) V(s,g;theta) that generalise not just over states s but also over goals g. We develop an efficient technique for supervised learning of UVFAs, by factoring observed values into separate embedding vectors for state and goal, and then learning a mapping from s and g to these factored embedding vectors. We show how this technique may be incorporated into a reinforcement learning algorithm that updates the UVFA solely from observed rewards. Finally, we demonstrate that a UVFA can successfully generalise to previously unseen goals.}
}

@article{kolve2017ai2,
  title={AI2-THOR: An Interactive 3D Environment for Visual AI},
  author={Kolve, Eric and Mottaghi, Roozbeh and Gordon, Daniel and Zhu, Yuke and Gupta, Abhinav and Farhadi, Ali},
  journal={arXiv preprint arXiv:1712.05474},
  year={2017}
}
@book{sutton1998reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  volume={1},
  number={1},
  year={1998},
  publisher={MIT press Cambridge}
}
@inproceedings{zhelo2018curiosity,
  booktitle={ICRA 2018 Workshop on Machine Learning in Planning and Control of Robot Motion},
  title={Curiosity-driven Exploration for Mapless Navigation with Deep Reinforcement Learning},
  author={Zhelo, Oleksii and Zhang, Jingwei and Tai, Lei and Liu, Ming and Burgard, Wolfram},
  year={2018},
  month={May},
}
@inproceedings{tai2018social,
  author={Tai, Lei and Zhang, Jingwei and Liu, Ming and Burgard, Wolfram},
  booktitle={2018 IEEE international conference on robotics and automation (ICRA)},
  title={Socially Compliant Navigation Through Raw Depth Inputs with Generative Adversarial Imitation Learning},
  year={2018},
  pages={1111-1117},
  doi={10.1109/ICRA.2018.8460968},
  ISSN={2577-087X},
  month={May},
}
@article{zhang2017neural,
  title={Neural slam: Learning to explore with external memory},
  author={Zhang, Jingwei and Tai, Lei and Boedecker, Joschka and Burgard, Wolfram and Liu, Ming},
  journal={arXiv preprint arXiv:1706.09520},
  year={2017}
}
@inproceedings{tai2017virtual,
  title={Virtual-to-real deep reinforcement learning: Continuous control of mobile robots for mapless navigation},
  author={Tai, Lei and Paolo, Giuseppe and Liu, Ming},
  booktitle={2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={31-36},
  year={2017},
  organization={IEEE}
}
@INPROCEEDINGS{sadeghi2016cad2rl,
  AUTHOR    = {Fereshteh Sadeghi AND Sergey Levine},
  TITLE     = {CAD2RL: Real Single-Image Flight Without a Single Real Image},
  BOOKTITLE = {Proceedings of Robotics: Science and Systems},
  YEAR      = {2017},
  ADDRESS   = {Cambridge, Massachusetts},
  MONTH     = {July},
  DOI       = {10.15607/RSS.2017.XIII.034}
}


@article{durrant2006simultaneous,
  title={Simultaneous localization and mapping: part I},
  author={Durrant-Whyte, Hugh and Bailey, Tim},
  journal={IEEE robotics \& automation magazine},
  volume={13},
  number={2},
  pages={99--110},
  year={2006},
  publisher={IEEE}
}

@inproceedings{sun2014wifi,
  title={WiFi signal strength-based robot indoor localization},
  author={Sun, Yuxiang and Liu, Ming and Meng, Max Q-H},
  booktitle={Information and Automation (ICIA), 2014 IEEE International Conference on},
  pages={250--256},
  year={2014},
  organization={IEEE}
}

@article{qiu2016let,
  title={Let the Light Guide Us: VLC-Based Localization},
  author={Qiu, Kejie and Zhang, Fangyi and Liu, Ming},
  journal={IEEE Robotics \& Automation Magazine},
  volume={23},
  number={4},
  pages={174--183},
  year={2016},
  publisher={IEEE}
}

@inproceedings{chen2015deepdriving,
  title={Deepdriving: Learning affordance for direct perception in autonomous driving},
  author={Chen, Chenyi and Seff, Ari and Kornhauser, Alain and Xiao, Jianxiong},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={2722--2730},
  year={2015}
}

@inproceedings{pfeiffer2016perception,
  title={From perception to decision: A data-driven approach to end-to-end motion planning for autonomous ground robots},
  author={Pfeiffer, Mark and Schaeuble, Michael and Nieto, Juan and Siegwart, Roland and Cadena, Cesar},
  booktitle={2018 IEEE international conference on robotics and automation (ICRA)},
  pages={1527--1533},
  year={2017},
  organization={IEEE}
}
@article{kober2013reinforcement,
  title={Reinforcement learning in robotics: A survey},
  author={Kober, Jens and Bagnell, J Andrew and Peters, Jan},
  journal={The International Journal of Robotics Research},
  volume={32},
  number={11},
  pages={1238--1274},
  year={2013},
  publisher={SAGE Publications Sage UK: London, England}
}
@inproceedings{ng2000algorithms,
  author    = {Andrew Y. Ng and
               Stuart J. Russell},
  title     = {Algorithms for Inverse Reinforcement Learning},
  booktitle = {Proceedings of the 17th International Conference on Machine Learning},
  pages     = {663--670},
  year      = {2000},
  timestamp = {Sun, 21 Feb 2010 20:54:50 +0100},
  biburl    = {https://dblp.org/rec/bib/conf/icml/NgR00},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{abbeel2004apprenticeship,
  title={Apprenticeship learning via inverse reinforcement learning},
  author={Abbeel, Pieter and Ng, Andrew Y},
  pages={1},
  booktitle = {Proceedings of the 21st International Conference on Machine Learning},
  year={2004},
}
@inproceedings{Chen17_IROS,
	author = {Yu Fan Chen and Michael Everett and Miao Liu and Jonathan P. How},
  booktitle={2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
	title = {Socially Aware Motion Planning with Deep Reinforcement Learning},
  pages={1343-1350},
	year = {2017},
  month={Sept}
}
@book{o1978hippocampus,
  title={The hippocampus as a cognitive map},
  author={O'keefe, John and Nadel, Lynn},
  year={1978},
  publisher={Oxford: Clarendon Press}
}

@article{mcnaughton2006path,
  title={Path integration and the neural basis of the'cognitive map'},
  author={McNaughton, Bruce L and Battaglia, Francesco P and Jensen, Ole and Moser, Edvard I and Moser, May-Britt},
  journal={Nature Reviews Neuroscience},
  volume={7},
  number={8},
  pages={663--678},
  year={2006},
  publisher={Nature Publishing Group}
}

@article{collett2004animal,
  title={Animal navigation: path integration, visual landmarks and cognitive maps},
  author={Collett, Thomas S and Graham, Paul},
  journal={Current Biology},
  volume={14},
  number={12},
  pages={R475--R477},
  year={2004},
  publisher={Elsevier}
}

@inproceedings{milford2004ratslam,
  title={RatSLAM: a hippocampal model for simultaneous localization and mapping},
  author={Milford, Michael J and Wyeth, Gordon F and Prasser, David},
  booktitle={2004 IEEE international conference on robotics and automation (ICRA)},
  volume={1},
  pages={403--408},
  year={2004},
  organization={IEEE}
}

@book{Lav06,
  author       = {S.M. LaValle},
  title        = {Planning Algorithms},
  publisher    = {Cambridge University Press},
  year         = {2006}
}

@book{Lat91,
  author       = {J.C. Latombe},
  title        = {Robot Motion Planning},
  publisher    = {Kluwer},
  year         = {1991}
}

@book{stachniss2009robotic,
  title={Robotic mapping and exploration},
  author={Stachniss, Cyrill},
  volume={55},
  year={2009},
  publisher={Springer}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Research}
}
@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}
@article{graves2014neural,
  title={Neural turing machines},
  author={Graves, Alex and Wayne, Greg and Danihelka, Ivo},
  journal={arXiv preprint arXiv:1410.5401},
  year={2014}
}

@article{graves2016hybrid,
  title={Hybrid computing using a neural network with dynamic external memory},
  author={Graves, Alex and Wayne, Greg and Reynolds, Malcolm and Harley, Tim and Danihelka, Ivo and Grabska-Barwi{\'n}ska, Agnieszka and Colmenarejo, Sergio G{\'o}mez and Grefenstette, Edward and Ramalho, Tiago and Agapiou, John and others},
  journal={Nature},
  volume={538},
  number={7626},
  pages={471--476},
  year={2016},
  publisher={Nature Research}
}
@article{kuipers1991robot,
  title={A robot exploration and mapping strategy based on a semantic hierarchy of spatial representations},
  author={Kuipers, Benjamin and Byun, Yung-Tai},
  journal={Robotics and autonomous systems},
  volume={8},
  number={1},
  pages={47--63},
  year={1991},
  publisher={Elsevier}
}
@article{lenz2015deep,
  title={Deep learning for detecting robotic grasps},
  author={Lenz, Ian and Lee, Honglak and Saxena, Ashutosh},
  journal={The International Journal of Robotics Research},
  volume={34},
  number={4-5},
  pages={705--724},
  year={2015},
  publisher={SAGE Publications}
}
@inproceedings{kim2006traversability,
  title={Traversability classification using unsupervised on-line visual learning for outdoor robot navigation},
  author={Kim, Dongshin and Sun, Jie and Oh, Sang Min and Rehg, James M and Bobick, Aaron F},
  booktitle={2006 IEEE international conference on robotics and automation (ICRA)},
  pages={518--525},
  year={2006},
  organization={IEEE}
}
@inproceedings{tao2015semi,
  title={Semi-supervised online learning for efficient classification of objects in 3D data streams},
  author={Tao, Ye and Triebel, Rudolph and Cremers, Daniel},
  booktitle={2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={2904--2910},
  year={2015},
  organization={IEEE}
}
@inproceedings{sukhbaatar2015end,
	title = {End-To-End Memory Networks},
	author = {Sukhbaatar, Sainbayar and szlam, arthur and Weston, Jason and Fergus, Rob},
	booktitle = {Advances in Neural Information Processing Systems 28},
	editor = {C. Cortes and N. D. Lawrence and D. D. Lee and M. Sugiyama and R. Garnett},
	pages = {2440--2448},
	year = {2015},
	publisher = {Curran Associates, Inc.},
	url = {http://papers.nips.cc/paper/5846-end-to-end-memory-networks.pdf}
}
@inproceedings{oh2016control,
  author = {Oh, Junhyuk and Chockalingam, Valliappa and Singh, Satinder and Lee, Honglak},
  title = {Control of Memory, Active Perception, and Action in Minecraft},
  booktitle = {Proceedings of the 33rd International Conference on International Conference on Machine Learning},
  series = ICML,
  year = {2016},
  location = {New York, NY, USA},
  pages = {2790--2799},
  numpages = {10},
  url = {http://dl.acm.org/citation.cfm?id=3045390.3045684},
  acmid = {3045684},
  publisher = {JMLR.org},
}
@article{blundell2016model,
  title={Model-free episodic control},
  author={Blundell, Charles and Uria, Benigno and Pritzel, Alexander and Li, Yazhe and Ruderman, Avraham and Leibo, Joel Z and Rae, Jack and Wierstra, Daan and Hassabis, Demis},
  journal={arXiv preprint arXiv:1606.04460},
  year={2016}
}

@article{pritzel2017neural,
  title={Neural Episodic Control},
  author={Pritzel, Alexander and Uria, Benigno and Srinivasan, Sriram and Puigdom{\`e}nech, Adri{\`a} and Vinyals, Oriol and Hassabis, Demis and Wierstra, Daan and Blundell, Charles},
  journal={arXiv preprint arXiv:1703.01988},
  year={2017}
}

%1. embeding well-established models into networks

@inproceedings{bengio2013deep,
  title={Deep learning of representations: Looking forward},
  author={Bengio, Yoshua},
  booktitle={International Conference on Statistical Language and Speech Processing},
  pages={1--37},
  year={2013},
  organization={Springer}
}

@inproceedings{tamar2016value,
  title={Value iteration networks},
  author={Tamar, Aviv and Wu, Yi and Thomas, Garrett and Levine, Sergey and Abbeel, Pieter},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2154--2162},
  year={2016}
}
@inproceedings{fischer2015flownet,
  title={Flownet: Learning optical flow with convolutional networks},
  author={Dosovitskiy, Alexey and Fischer, Philipp and Ilg, Eddy and Hausser, Philip and Hazirbas, Caner and Golkov, Vladimir and Van Der Smagt, Patrick and Cremers, Daniel and Brox, Thomas},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={2758--2766},
  year={2015}
}

%3. deep reinforment learning for navigation}

@article{tai2016deep_survey,
  title={Deep-learning in Mobile Robotics-from Perception to Control Systems: A Survey on Why and Why not},
  author={Tai, Lei and Liu, Ming},
  journal={arXiv preprint arXiv:1612.07139},
  year={2016}
}

@article{tai2016towards,
  title={Towards cognitive exploration through deep reinforcement learning for mobile robots},
  author={Tai, Lei and Liu, Ming},
  journal={arXiv preprint arXiv:1610.01733},
  year={2016}
}

@inproceedings{mirowski2016learning,
  title={Learning to navigate in complex environments},
  author={Mirowski, Piotr and Pascanu, Razvan and Viola, Fabio and Soyer, Hubert and Ballard, Andy and Banino, Andrea and Denil, Misha and Goroshin, Ross and Sifre, Laurent and Kavukcuoglu, Koray and others},
  booktitle={International Conference on Learning Representations},
  year={2017}
}
@inproceedings{gupta2017cognitive,
  title={Cognitive Mapping and Planning for Visual Navigation},
  author={Gupta, Saurabh and Davidson, James and Levine, Sergey and Sukthankar, Rahul and Malik, Jitendra},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2616--2625},
  year={2017}
}

@InProceedings{parisotto2017neural,
  title={ Neural Map: Structured Memory for Deep Reinforcement Learning},
  author={Emilio Parisotto and Ruslan Salakhutdinov},
  booktitle={International Conference on Learning Representations},
  year={2018},
  url={https://openreview.net/forum?id=Bk9zbyZCZ},
}

@article{bhatti2016playing,
  title={Playing doom with slam-augmented deep reinforcement learning},
  author={Bhatti, Shehroze and Desmaison, Alban and Miksik, Ondrej and Nardelli, Nantas and Siddharth, N and Torr, Philip HS},
  journal={arXiv preprint arXiv:1612.00380},
  year={2016}
}

@inproceedings{mnih2016asynchronous,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle = {Proceedings of The 33rd International Conference on Machine Learning},
  pages={1928--1937},
  year={2016}
}

@inproceedings{shen2012autonomous,
  title={Autonomous indoor 3D exploration with a micro-aerial vehicle},
  author={Shen, Shaojie and Michael, Nathan and Kumar, Vijay},
  booktitle={2012 IEEE international conference on robotics and automation (ICRA)},
  pages={9--15},
  year={2012},
  organization={IEEE}
}

@inproceedings{chaplot2018active,
  title={Active Neural Localization},
  author={Chaplot, Devendra Singh and Parisotto, Emilio and Salakhutdinov, Ruslan},
  booktitle={International Conference on Learning Representations},
  year={2018}
}
@inproceedings{kanitscheider2017training,
  title={Training recurrent networks to generate hypotheses about how the brain solves hard navigation problems},
  author={Kanitscheider, Ingmar and Fiete, Ila},
  booktitle={Advances in Neural Information Processing Systems 30},
  pages={4532--4541},
  year={2017}
}
@article{gupta2017unifying,
  title={Unifying map and landmark based representations for visual navigation},
  author={Gupta, Saurabh and Fouhey, David and Levine, Sergey and Malik, Jitendra},
  journal={arXiv preprint arXiv:1712.08125},
  year={2017}
}
@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}

@article{funahashi1993approximation,
  title={Approximation of dynamical systems by continuous time recurrent neural networks},
  author={Funahashi, Ken-ichi and Nakamura, Yuichi},
  journal={Neural networks},
  volume={6},
  number={6},
  pages={801--806},
  year={1993},
  publisher={Elsevier}
}
@inproceedings{okal2016learning,
  title={Learning socially normative robot navigation behaviors with bayesian inverse reinforcement learning},
  author={Okal, Billy and Arras, Kai O},
  booktitle={2016 IEEE international conference on robotics and automation (ICRA)},
  pages={2889--2895},
  year={2016},
  organization={IEEE}
}
@inproceedings{long2018towards,
  title={Towards optimally decentralized multi-robot collision avoidance via deep reinforcement learning},
  author={Long, Pinxin and Fanl, Tingxiang and Liao, Xinyi and Liu, Wenxi and Zhang, Hao and Pan, Jia},
  booktitle={2018 IEEE international conference on robotics and automation (ICRA)},
  pages={6252--6259},
  year={2018},
  organization={IEEE}
}
@inproceedings{pathak2017curiosity,
  title = 	 {Curiosity-driven Exploration by Self-supervised Prediction},
  author = 	 {Deepak Pathak and Pulkit Agrawal and Alexei A. Efros and Trevor Darrell},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {2778--2787},
  year = 	 {2017},
  editor = 	 {Doina Precup and Yee Whye Teh},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {International Convention Centre, Sydney, Australia},
  month = 	 {06--11 Aug},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v70/pathak17a/pathak17a.pdf},
  url = 	 {http://proceedings.mlr.press/v70/pathak17a.html},
  abstract = 	 {In many real-world scenarios, rewards extrinsic to the agent are extremely sparse, or absent altogether. In such cases, curiosity can serve as an intrinsic reward signal to enable the agent to explore its environment and learn skills that might be useful later in its life. We formulate curiosity as the error in an agent’s ability to predict the consequence of its own actions in a visual feature space learned by a self-supervised inverse dynamics model. Our formulation scales to high-dimensional continuous state spaces like images, bypasses the difficulties of directly predicting pixels, and, critically, ignores the aspects of the environment that cannot affect the agent. The proposed approach is evaluated in two environments: VizDoom and Super Mario Bros. Three broad settings are investigated: 1) sparse extrinsic reward, where curiosity allows for far fewer interactions with the environment to reach the goal; 2) exploration with no extrinsic reward, where curiosity pushes the agent to explore more efficiently; and 3) generalization to unseen scenarios (e.g. new levels of the same game) where the knowledge gained from earlier experience helps the agent explore new places much faster than starting from scratch.}
}


@article{liang2017plugo,
  title={Plugo: A VLC systematic perspective of large-scale indoor localization},
  author={Liang, Qing and Liu, Ming},
  journal={arXiv preprint arXiv:1709.06926},
  year={2017}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@misc{Bulldog,
  title = {Ros Robots: Bulldog},
  author= {Bulldog},
  howpublished = {\url{https://robots.ros.org/bulldog/}},
}
@misc{videvo,
  author= {Videvo},
  howpublished = {\url{http://www.videvo.net}},
  title = {Videvo free footage},
  year={2016}
}

@book{ abelson-et-al:scheme,
  author = "Harold Abelson and Gerald~Jay Sussman and Julie Sussman",
  title = "Structure and Interpretation of Computer Programs",
  publisher = "MIT Press",
  address = "Cambridge, Massachusetts",
  year = "1985"
}
@inproceedings{koenig2004design,
  title={Design and use paradigms for gazebo, an open-source multi-robot simulator},
  author={Koenig, Nathan and A, B and Howard, Andrew},
  booktitle={2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  volume={3},
  pages={2149--2154},
  year={2004},
  organization={IEEE}
}
@inproceedings{ bgf:Lixto,
  author = "Robert Baumgartner and Georg Gottlob and Sergio Flesca",
  title = "Visual Information Extraction with {Lixto}",
  booktitle = "Proceedings of the 27th International Conference on Very Large Databases",
  pages = "119--128",
  publisher = "Morgan Kaufmann",
  address = "Rome, Italy",
  month = "September",
  year = "2001"
}
@article{ brachman-schmolze:kl-one,
  author = "Ronald~J. Brachman and James~G. Schmolze",
  title = "An overview of the {KL-ONE} knowledge representation system",
  journal = "Cognitive Science",
  volume = "9",
  number = "2",
  pages = "171--216",
  month = "April--June",
  year = "1985"
}
@article{ gottlob:nonmon,
  author = "Georg Gottlob",
  title = "Complexity results for nonmonotonic logics",
  journal = "Journal of Logic and Computation",
  volume = "2",
  number = "3",
  pages = "397--425",
  month = "June",
  year = "1992"
}
@article{ gls:hypertrees,
  author = "Georg Gottlob and Nicola Leone and Francesco Scarcello",
  title = "Hypertree Decompositions and Tractable Queries",
  journal = "Journal of Computer and System Sciences",
  volume = "64",
  number = "3",
  pages = "579--627",
  month = "May",
  year = "2002"
}
@article{ levesque:functional-foundations,
  author = "Hector~J. Levesque",
  title = "Foundations of a functional approach to knowledge representation",
  journal = "Artificial Intelligence",
  volume = "23",
  number = "2",
  pages = "155--212",
  month = "July",
  year = "1984"
}
@inproceedings{ levesque:belief,
  author = "Hector~J. Levesque",
  title = "A logic of implicit and explicit belief",
  booktitle = "Proceedings of the Fourth National Conference on Artificial Intelligence",
  publisher = "American Association for Artificial Intelligence",
  pages = "198--202",
  address = "Austin, Texas",
  month = "August",
  year = "1984"
}
@article{ nebel:jair-2000,
  author = "Bernhard Nebel",
  title = "On the compilability and expressive power of propositional planning formalisms",
  journal = "Journal of Artificial Intelligence Research",
  volume = "12",
  pages = "271--315",
  year = "2000"
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% else
@article{simonyan2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}
@article{zhang2017mixup,
  title={mixup: Beyond Empirical Risk Minimization},
  author={Zhang, Hongyi and Cisse, Moustapha and Dauphin, Yann N and Lopez-Paz, David},
  journal={arXiv preprint arXiv:1710.09412},
  year={2017}
}


% artistic style transfer
@inproceedings{gatys2015neural,
  title={Image style transfer using convolutional neural networks},
  author={Gatys, Leon A and Ecker, Alexander S and Bethge, Matthias},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2414--2423},
  year={2016}
}
@inproceedings{ulyanov2016texture,
  title = 	 {Texture Networks: Feed-forward Synthesis of Textures and Stylized Images},
  author = 	 {Dmitry Ulyanov and Vadim Lebedev and  Andrea and Victor Lempitsky},
  booktitle = 	 {Proceedings of The 33rd International Conference on Machine Learning},
  pages = 	 {1349--1357},
  year = 	 {2016},
  editor = 	 {Maria Florina Balcan and Kilian Q. Weinberger},
  volume = 	 {48},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {New York, New York, USA},
  month = 	 {20--22 Jun},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v48/ulyanov16.pdf},
  url = 	 {http://proceedings.mlr.press/v48/ulyanov16.html},
  abstract = 	 {Gatys et al. recently demonstrated that deep networks can generate beautiful textures and stylized images from a single texture example. However, their methods requires a slow and memory-consuming optimization process. We propose here an alternative approach that moves the computational burden to a learning stage. Given a single example of a texture, our approach trains compact feed-forward convolutional networks to generate multiple samples of the same texture of arbitrary size and to transfer artistic style from a given image to any other image. The resulting networks are remarkably light-weight and can generate textures of quality comparable to Gatys et al., but hundreds of times faster. More generally, our approach highlights the power and flexibility of generative feed-forward models trained with complex and expressive loss functions.}
}
@inproceedings{johnson2016perceptual,
  title={Perceptual losses for real-time style transfer and super-resolution},
  author={Johnson, Justin and Alahi, Alexandre and Fei-Fei, Li},
  booktitle={The European Conference on Computer Vision (ECCV)},
  pages={694--711},
  year={2016},
  organization={Springer}
}
@misc{Ulyanov2016onlinedoodle,
  author = {Ulyanov, Dmitry},
  title = {Online Neural Doodle},
  year = {2016},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/DmitryUlyanov/online-neural-doodle}},
}


% artistic style transfer for videos
@inproceedings{ruder2016artistic,
  title={Artistic style transfer for videos},
  author={Ruder, Manuel and Dosovitskiy, Alexey and Brox, Thomas},
  booktitle={German Conference on Pattern Recognition},
  pages={26--36},
  year={2016},
  organization={Springer}
}
@article{ruder2017artistic,
  title={Artistic style transfer for videos and spherical images},
  author={Ruder, Manuel and Dosovitskiy, Alexey and Brox, Thomas},
  journal={International Journal of Computer Vision},
  pages={1--21},
  year={2018},
  publisher={Springer}
}
@inproceedings{huang2017real,
  title={Real-time neural style transfer for videos},
  author={Huang, Haozhi and Wang, Hao and Luo, Wenhan and Ma, Lin and Jiang, Wenhao and Zhu, Xiaolong and Li, Zhifeng and Liu, Wei},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={783--791},
  year={2017}
}
@inproceedings{jaderberg2015spatial,
  title={Spatial transformer networks},
  author={Jaderberg, Max and Simonyan, Karen and Zisserman, Andrew and others},
  booktitle={Advances in Neural Information Processing Systems 28},
  pages={2017--2025},
  year={2015}
}
% domain adaption
@inproceedings{zhu2017unpaired,
  title={Unpaired Image-To-Image Translation Using Cycle-Consistent Adversarial Networks},
  author={Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2223--2232},
  year={2017}
}

@InProceedings{hoffman2017cycada,
  title = 	 {{C}y{CADA}: Cycle-Consistent Adversarial Domain Adaptation},
  author = 	 {Hoffman, Judy and Tzeng, Eric and Park, Taesung and Zhu, Jun-Yan and Isola, Phillip and Saenko, Kate and Efros, Alexei and Darrell, Trevor},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {1989--1998},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Stockholmsmässan, Stockholm Sweden},
  month = 	 {10--15 Jul},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/hoffman18a/hoffman18a.pdf},
  url = 	 {http://proceedings.mlr.press/v80/hoffman18a.html},
  abstract = 	 {Domain adaptation is critical for success in new, unseen environments. Adversarial adaptation models have shown tremendous progress towards adapting to new environments by focusing either on discovering domain invariant representations or by mapping between unpaired image domains. While feature space methods are difficult to interpret and sometimes fail to capture pixel-level and low-level domain shifts, image space methods sometimes fail to incorporate high level semantic knowledge relevant for the end task. We propose a model which adapts between domains using both generative image space alignment and latent representation space alignment. Our approach, Cycle-Consistent Adversarial Domain Adaptation (CyCADA), guides transfer between domains according to a specific discriminatively trained task and avoids divergence by enforcing consistency of the relevant semantics before and after adaptation. We evaluate our method on a variety of visual recognition and prediction settings, including digit classification and semantic segmentation of road scenes, advancing state-of-the-art performance for unsupervised adaptation from synthetic to real world driving domains.}
}

@article{tzeng2014deep,
  title={Deep domain confusion: Maximizing for domain invariance},
  author={Tzeng, Eric and Hoffman, Judy and Zhang, Ning and Saenko, Kate and Darrell, Trevor},
  journal={arXiv preprint arXiv:1412.3474},
  year={2014}
}
@article{yu2015multi,
  title={Multi-scale context aggregation by dilated convolutions},
  author={Yu, Fisher and Koltun, Vladlen},
  journal={arXiv preprint arXiv:1511.07122},
  year={2015}
}
@inproceedings{rusu2016sim,
  title = 	 {Sim-to-Real Robot Learning from Pixels with Progressive Nets},
  author = 	 {Andrei A. Rusu and Matej Večerík and Thomas Rothörl and Nicolas Heess and Razvan Pascanu and Raia Hadsell},
  booktitle = 	 {Proceedings of the 1st Annual Conference on Robot Learning},
  pages = 	 {262--270},
  year = 	 {2017},
  editor = 	 {Sergey Levine and Vincent Vanhoucke and Ken Goldberg},
  volume = 	 {78},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {},
  month = 	 {13--15 Nov},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v78/rusu17a/rusu17a.pdf},
  url = 	 {http://proceedings.mlr.press/v78/rusu17a.html},
  abstract = 	 {Applying end-to-end learning to solve complex, interactive, pixel-driven control tasks on a robot is an unsolved problem. Deep Reinforcement Learning algorithms are too slow to achieve performance on a real robot, but their potential has been demonstrated in simulated environments. We propose using \emphprogressive networks to bridge the reality gap and transfer learned policies from simulation to the real world. The progressive net approach is a general framework that enables reuse of everything from low-level visual features to high-level policies for transfer to new tasks, enabling a compositional, yet simple, approach to building complex skills. We present an early demonstration of this approach with a number of experiments in the domain of robot manipulation that focus on bridging the reality gap. Unlike other proposed approaches, our real-world experiments demonstrate successful task learning from raw visual input on a fully actuated robot manipulator. Moreover, rather than relying on model-based trajectory optimisation, the task learning is accomplished using only deep reinforcement learning and sparse rewards.}
}

@InProceedings{bousmalis2017using,
  title={Using simulation and domain adaptation to improve efficiency of deep robotic grasping},
  author={Bousmalis, Konstantinos and Irpan, Alex and Wohlhart, Paul and Bai, Yunfei and Kelcey, Matthew and Kalakrishnan, Mrinal and Downs, Laura and Ibarz, Julian and Pastor, Peter and Konolige, Kurt and others},
  year={2018},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={4243-4250},
  keywords={image colour analysis;manipulators;neurocontrollers;robot vision;deep robotic grasping;off-the-shelf simulators;ground-truth annotations;randomized simulated environments;domain adaptation methods;grasping system;raw monocular RGB images;pixel-level domain adaptation;real-world grasping performance;annotated visual grasping datasets;GraspGAN;generative adversial network;Grasping;Robots;Training;Feature extraction;Adaptation models;Cameras;Task analysis},
  doi={10.1109/ICRA.2018.8460875},
  ISSN={2577-087X},
  month={May}
}

@inproceedings{tobin2017domain,
  title={Domain randomization for transferring deep neural networks from simulation to the real world},
  author={Tobin, Josh and Fong, Rachel and Ray, Alex and Schneider, Jonas and Zaremba, Wojciech and Abbeel, Pieter},
  booktitle={2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={23--30},
  year={2017},
  organization={IEEE}
}

% drl
@inproceedings{hasselt2010double,
  title={Double Q-learning},
  author={Hasselt, Hado V},
  booktitle={Advances in Neural Information Processing Systems 23},
  pages={2613--2621},
  year={2010}
}
% drl in robotics
%  booktitle={Robotics and Automation (ICRA), 2017 IEEE International Conference on},

% dataset
@inproceedings{butler2012naturalistic,
  title={A naturalistic open source movie for optical flow evaluation},
  author={Butler, Daniel J and Wulff, Jonas and Stanley, Garrett B and Black, Michael J},
  booktitle=ECCV,
  pages={611--625},
  year={2012},
  organization={Springer}
}
@inproceedings{cordts2016cityscapes,
  title={The cityscapes dataset for semantic urban scene understanding},
  author={Cordts, Marius and Omran, Mohamed and Ramos, Sebastian and Rehfeld, Timo and Enzweiler, Markus and Benenson, Rodrigo and Franke, Uwe and Roth, Stefan and Schiele, Bernt},
  booktitle=CVPR,
  pages={3213--3223},
  year={2016}
}
@article{savva2017minos,
  title={MINOS: Multimodal Indoor Simulator for Navigation in Complex Environments},
  author={Savva, Manolis and Chang, Angel X and Dosovitskiy, Alexey and Funkhouser, Thomas and Koltun, Vladlen},
  journal={arXiv preprint arXiv:1712.03931},
  year={2017}
}
@article{RobotCarDatasetIJRR,
  Author = {Will Maddern and Geoff Pascoe and Chris Linegar and Paul Newman},
  Title = {{1 Year, 1000km: The Oxford RobotCar Dataset}},
  Journal = {The International Journal of Robotics Research (IJRR)},
  Volume = {36},
  Number = {1},
  Pages = {3-15},
  Year = {2017},
  doi = {10.1177/0278364916679498},
  URL =
{http://dx.doi.org/10.1177/0278364916679498},
  eprint =
{http://ijr.sagepub.com/content/early/2016/11/28/0278364916679498.full.pdf+html},
  Pdf = {http://robotcar-dataset.robots.ox.ac.uk/images/robotcar_ijrr.pdf}}

@inproceedings{nagabandi2018neural,
  title={Neural network dynamics for model-based deep reinforcement learning with model-free fine-tuning},
  author={Nagabandi, Anusha and Kahn, Gregory and Fearing, Ronald S and Levine, Sergey},
  booktitle={2018 IEEE international conference on robotics and automation (ICRA)},
  pages={7559--7566},
  year={2018},
  organization={IEEE}
}

@inproceedings{xu2018algorithmic,
  title={Algorithmic Framework for Model-based Deep Reinforcement Learning with Theoretical Guarantees},
  author={Yuping Luo and Huazhe Xu and Yuanzhi Li and Yuandong Tian and Trevor Darrell and Tengyu Ma},
  booktitle={International Conference on Learning Representations},
  year={2019},
  url={https://openreview.net/forum?id=BJe1E2R5KX},
}


@article{rybkin2018unsupervised,
  title={Unsupervised learning of sensorimotor affordances by stochastic future prediction},
  author={Rybkin, Oleh and Pertsch, Karl and Jaegle, Andrew and Derpanis, Konstantinos G and Daniilidis, Kostas},
  journal={arXiv preprint arXiv:1806.09655},
  year={2018}
}
@inproceedings{ebert2017self,
  title = 	 {Self-Supervised Visual Planning with Temporal Skip Connections },
  author = 	 {Frederik Ebert and Chelsea Finn and Alex X. Lee and Sergey Levine},
  booktitle = 	 {Proceedings of the 1st Annual Conference on Robot Learning},
  pages = 	 {344--356},
  year = 	 {2017},
  editor = 	 {Sergey Levine and Vincent Vanhoucke and Ken Goldberg},
  volume = 	 {78},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {},
  month = 	 {13--15 Nov},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v78/frederik ebert17a/frederik ebert17a.pdf},
  url = 	 {http://proceedings.mlr.press/v78/frederik-ebert17a.html},
  abstract = 	 {In order to autonomously learn wide repertoires of complex skills, robots must be able to learn from their own autonomously collected data, without human supervision. One learning signal that is always available for autonomously collected data is prediction. If a robot can learn to predict the future, it can use this predictive model to take actions to produce desired outcomes, such as moving an object to a particular location. However, in complex open-world scenarios, designing a representation for prediction is difficult. In this work, we instead aim to enable self-supervised robot learning through direct video prediction: instead of attempting to design a good representation, we directly predict what the robot will see next, and then use this model to achieve desired goals. A key challenge in video prediction for robotic manipulation is handling complex spatial arrangements such as occlusions. To that end, we introduce a video prediction model that can keep track of objects through occlusion by incorporating temporal skip-connections. Together with a novel planning criterion and action space formulation, we demonstrate that this model substantially outperforms prior work on video prediction-based control. Our results show manipulation of objects not seen during training, handling multiple objects, and pushing objects around obstructions. These results represent a significant advance in the range and complexity of skills that can be performed entirely with self-supervised robot learning. }
}

@inproceedings{finn2017deep,
  title={Deep visual foresight for planning robot motion},
  author={Finn, Chelsea and Levine, Sergey},
  booktitle={2017 IEEE international conference on robotics and automation (ICRA)},
  pages={2786--2793},
  year={2017},
  organization={IEEE}
}

@inproceedings{ebert2018robustness,
  title = 	 {Robustness via Retrying: Closed-Loop Robotic Manipulation with Self-Supervised Learning},
  author = 	 {Ebert, Frederik and Dasari, Sudeep and Lee, Alex X. and Levine, Sergey and Finn, Chelsea},
  booktitle = 	 {Proceedings of The 2nd Conference on Robot Learning},
  pages = 	 {983--993},
  year = 	 {2018},
  editor = 	 {Billard, Aude and Dragan, Anca and Peters, Jan and Morimoto, Jun},
  volume = 	 {87},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {},
  month = 	 {29--31 Oct},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v87/ebert18a/ebert18a.pdf},
  url = 	 {http://proceedings.mlr.press/v87/ebert18a.html},
  abstract = 	 {Prediction is an appealing objective for self-supervised learning of behavioral skills, particularly for autonomous robots. However, effectively utilizing predictive models for control, especially with raw image inputs, poses a number of major challenges. How should the predictions be used? What happens when they are inaccurate? In this paper, we tackle these questions by proposing a method for learning robotic skills from raw image observations, using only autonomously collected experience. We show that even an imperfect model can complete complex tasks if it can continuously retry, but this requires the model to not lose track of the objective (e.g., the object of interest). To enable a robot to continuously retry a task, we devise a self-supervised algorithm for learning image registration, which can keep track of objects of interest for the duration of the trial. We demonstrate that this idea can be combined with a video-prediction based controller to enable complex behaviors to be learned from scratch using only raw visual inputs, including grasping, repositioning objects, and non-prehensile manipulation. Our real-world experiments demonstrate that a model trained with 160 robot hours of autonomously collected, unlabeled data is able to successfully perform complex manipulation tasks with a wide range of objects not seen during training.}
}

@InProceedings{Rhinehart_2018_ECCV,
  author = {Rhinehart, Nicholas and Kitani, Kris M. and Vernaza, Paul},
  title = {R2P2: A ReparameteRized Pushforward Policy for Diverse, Precise Generative Path Forecasting},
  booktitle = {The European Conference on Computer Vision (ECCV)},
  month = {September},
  year = {2018}
}
@article{rhinehart2018deep,
  title={Deep Imitative Models for Flexible Inference, Planning, and Control},
  author={Rhinehart, Nicholas and McAllister, Rowan and Levine, Sergey},
  journal={arXiv preprint arXiv:1810.06544},
  year={2018}
}
@article{deisenroth2013survey,
  title={A survey on policy search for robotics},
  author={Deisenroth, Marc Peter and Neumann, Gerhard and Peters, Jan and others},
  journal={Foundations and Trends{\textregistered} in Robotics},
  volume={2},
  number={1--2},
  pages={1--142},
  year={2013},
  publisher={Now Publishers, Inc.}
}
@InProceedings{kurutach2018model,
  title={Model-Ensemble Trust-Region Policy Optimization},
  author={Kurutach, Thanard and Clavera, Ignasi and Duan, Yan and Tamar, Aviv and Abbeel, Pieter},
  booktitle={International Conference on Learning Representations},
  year={2018}
}
@InProceedings{chua2018deep,
  title = {Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models},
  author = {Chua, Kurtland and Calandra, Roberto and McAllister, Rowan and Levine, Sergey},
  booktitle = {Advances in Neural Information Processing Systems 31},
  editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
  pages = {4754--4765},
  year = {2018},
  publisher = {Curran Associates, Inc.},
  url = {http://papers.nips.cc/paper/7725-deep-reinforcement-learning-in-a-handful-of-trials-using-probabilistic-dynamics-models.pdf}
}
@inproceedings{he2017mask,
  title={Mask r-cnn},
  author={He, Kaiming and Gkioxari, Georgia and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={2980--2988},
  year={2017},
  organization={IEEE}
}

@InProceedings{yang2018eccv,
  author="Yang, Luona and Liang, Xiaodan and Wang, Tairui and Xing, Eric",
  title="Real-to-Virtual Domain Unification for End-to-End Autonomous Driving",
  booktitle = {The European Conference on Computer Vision (ECCV)},
  year="2018",
  publisher="Springer International Publishing",
  address="Cham",
  pages="553--570",
}

@inproceedings{kendall2017uncertainties,
	title = {What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?},
	author = {Kendall, Alex and Gal, Yarin},
	booktitle = {Advances in Neural Information Processing Systems 30},
	editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
	pages = {5574--5584},
	year = {2017},
	publisher = {Curran Associates, Inc.},
	url = {http://papers.nips.cc/paper/7141-what-uncertainties-do-we-need-in-bayesian-deep-learning-for-computer-vision.pdf}
}

@book{Thrun05,
  author =	 {Thrun, Sebastian and Burgard, Wolfram and Fox,Dieter},
  title =	 {Probabilistic Robotics},
  year =	 2005,
  publisher =	 {MIT Press}
}
@inproceedings{goodfellow2014generative,
  title = {Generative Adversarial Nets},
  author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  booktitle = {Advances in Neural Information Processing Systems 27},
  editor = {Z. Ghahramani and M. Welling and C. Cortes and N. D. Lawrence and K. Q. Weinberger},
  pages = {2672--2680},
  year = {2014},
  publisher = {Curran Associates, Inc.},
  url = {http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf}
}


@inproceedings{dosovitskiy2017carla,
  title = 	 {{CARLA}: {An} Open Urban Driving Simulator},
  author = 	 {Alexey Dosovitskiy and German Ros and Felipe Codevilla and Antonio Lopez and Vladlen Koltun},
  booktitle = 	 {Proceedings of the 1st Annual Conference on Robot Learning},
  pages = 	 {1--16},
  year = 	 {2017},
  editor = 	 {Sergey Levine and Vincent Vanhoucke and Ken Goldberg},
  volume = 	 {78},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {},
  month = 	 {13--15 Nov},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v78/dosovitskiy17a/dosovitskiy17a.pdf},
  url = 	 {http://proceedings.mlr.press/v78/dosovitskiy17a.html},
  abstract = 	 {We introduce CARLA, an open-source simulator for autonomous driving research. CARLA has been developed from the ground up to support development, training, and validation of autonomous urban driving systems. In addition to open-source code and protocols, CARLA provides open digital assets (urban layouts, buildings, vehicles) that were created for this purpose and can be used freely. The simulation platform supports flexible specification of sensor suites and environmental conditions. We use CARLA to study the performance of three approaches to autonomous driving: a classic modular pipeline, an end-to-end model trained via imitation learning, and an end-to-end model trained via reinforcement learning. The approaches are evaluated in controlled scenarios of increasing difficulty, and their performance is examined via metrics provided by CARLA, illustrating the platform’s utility for autonomous driving research.}
}

@inproceedings{Codevilla2018,
  title={End-to-end driving via conditional imitation learning},
  author={Codevilla, Felipe and Miiller, Matthias and L{\'o}pez, Antonio and Koltun, Vladlen and Dosovitskiy, Alexey},
  booktitle={2018 IEEE international conference on robotics and automation (ICRA)},
  pages={1--9},
  year={2018},
  organization={IEEE}
}

@ARTICLE{zhang2019vrgoggles,
  author={Zhang, Jingwei and Tai, Lei and Yun, Peng and Xiong, Yufeng and Liu, Ming and Boedecker, Joschka and Burgard, Wolfram},
  journal={IEEE Robotics and Automation Letters},
  title={VR-Goggles for Robots: Real-to-Sim Domain Adaptation for Visual Control},
  year={2019},
  volume={4},
  number={2},
  pages={1148-1155},
  keywords={Visualization;Training;Robots;Adaptation models;Semantics;Task analysis;Navigation;Deep learning in robotics and automation;visual-based navigation;model learning for control},
  doi={10.1109/LRA.2019.2894216},
  ISSN={2377-3766},
  month={April},
}

@article{lutjens2018safe,
  title={Safe Reinforcement Learning with Model Uncertainty Estimates},
  author={L{\"u}tjens, Bj{\"o}rn and Everett, Michael and How, Jonathan P},
  journal={arXiv preprint arXiv:1810.08700},
  year={2018}
}
@phdthesis{pfeiffer2018learning,
  title={Learning to Navigate: Data-driven Motion Planning for Autonomous Ground Robots},
  author={Pfeiffer, Mark},
  year={2018},
  school={ETH Zurich}
}
@InProceedings{Liang_2018_ECCV,
  author = {Liang, Xiaodan and Wang, Tairui and Yang, Luona and Xing, Eric},
  title = {CIRL: Controllable Imitative Reinforcement Learning for Vision-based Self-driving},
  booktitle = {The European Conference on Computer Vision (ECCV)},
  month = {September},
  year = {2018}
}

@InProceedings{mueller18corl,
  title = 	 {Driving Policy Transfer via Modularity and Abstraction},
  author = 	 {Mueller, Matthias and Dosovitskiy, Alexey and Ghanem, Bernard and Koltun, Vladlen},
  booktitle = 	 {Proceedings of The 2nd Conference on Robot Learning},
  pages = 	 {1--15},
  year = 	 {2018},
  editor = 	 {Billard, Aude and Dragan, Anca and Peters, Jan and Morimoto, Jun},
  volume = 	 {87},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {},
  month = 	 {29--31 Oct},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v87/mueller18a/mueller18a.pdf},
  url = 	 {http://proceedings.mlr.press/v87/mueller18a.html},
  abstract = 	 {End-to-end approaches to autonomous driving have high sample complexity and are difficult to scale to realistic urban driving. Simulation can help end-to-end driving systems by providing a cheap, safe, and diverse training environment. Yet training driving policies in simulation brings up the problem of transferring such policies to the real world. We present an approach to transferring driving policies from simulation to reality via modularity and abstraction. Our approach is inspired by classic driving systems and aims to combine the benefits of modular architectures and end-to-end deep learning approaches. The key idea is to encapsulate the driving policy such that it is not directly exposed to raw perceptual input or low-level vehicle dynamics. We evaluate the presented approach in simulated urban environments and in the real world. In particular, we transfer a driving policy trained in simulation to a 1/5-scale robotic truck that is deployed in a variety of conditions, with no finetuning, on two continents.}
}

@INPROCEEDINGS{tl_rcar_2016,
  author={Tai, Lei and Liu, Ming},
  booktitle={2016 IEEE International Conference on Real-time Computing and Robotics (RCAR)},
  title={A robot exploration strategy based on Q-learning network},
  year={2016},
  pages={57-62},
  doi={10.1109/RCAR.2016.7784001},
  month={June}
}
@article{guzel2013autonomous,
  title={Autonomous vehicle navigation using vision and mapless strategies: a survey},
  author={G{\"u}zel, Mehmet Serdar},
  journal={Advances in Mechanical Engineering},
  volume={5},
  pages={234747},
  year={2013},
  publisher={SAGE Publications Sage UK: London, England}
}
@article{guerrero2005visual,
  title={Visual map-less navigation based on homographies},
  author={Guerrero, Jos{\'e} Jes{\'u}s and Martinez-Cantin, Ruben and Sag{\"u}{\'e}s, Carlos},
  journal={Journal of Robotic Systems},
  volume={22},
  number={10},
  pages={569--581},
  year={2005},
  publisher={Wiley Online Library}
}
@inproceedings{kamon1999range,
  title={Range-sensor based navigation in three dimensions},
  author={Kamon, Ishay and Rimon, Elon and Rivlin, Ehud},
  booktitle={1999 IEEE international conference on robotics and automation (ICRA)},
  volume={1},
  pages={163--169},
  year={1999},
  organization={IEEE}
}
@inproceedings{ulrich1998vfh+,
  title={VFH+: Reliable obstacle avoidance for fast mobile robots},
  author={Ulrich, Iwan and Borenstein, Johann},
  booktitle={1998 IEEE international conference on robotics and automation (ICRA)},
  volume={2},
  pages={1572--1577},
  year={1998},
  organization={IEEE}
}
@article{bonin2008visual,
  title={Visual navigation for mobile robots: A survey},
  author={Bonin-Font, Francisco and Ortiz, Alberto and Oliver, Gabriel},
  journal={Journal of intelligent and robotic systems},
  volume={53},
  number={3},
  pages={263--296},
  year={2008},
  publisher={Kluwer Academic Publishers}
}
@article{guzel2012behaviour,
  title={A behaviour-based architecture for mapless navigation using vision},
  author={Guzel, Mehmet Serdar and Bicker, Robert},
  journal={International Journal of Advanced Robotic Systems},
  volume={9},
  number={1},
  pages={18},
  year={2012},
  publisher={SAGE Publications}
}
@inproceedings{tai2016deep,
  author={Tai, Lei and Li, Shaohua and Liu, Ming},
  booktitle={2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title={A deep-network solution towards model-less obstacle avoidance},
  year={2016},
  pages={2759-2764},
  doi={10.1109/IROS.2016.7759428},
  ISSN={2153-0866},
  month={Oct},
}
@article{arkin1990integrating,
  title={Integrating behavioral, perceptual, and world knowledge in reactive navigation},
  author={Arkin, Ronald C},
  journal={Robotics and autonomous systems},
  volume={6},
  number={1},
  pages={105--122},
  year={1990},
  publisher={Elsevier}
}
@article{borenstein1991vector,
  title={The vector field histogram-fast obstacle avoidance for mobile robots},
  author={Borenstein, Johann and Koren, Yoram},
  journal={IEEE Transactions on Robotics and Automation},
  volume={7},
  number={3},
  pages={278--288},
  year={1991},
  publisher={IEEE}
}
@article{liu2013visual,
  title={Visual homing from scale with an uncalibrated omnidirectional camera},
  author={Liu, Ming and Pradalier, Cedric and Siegwart, Roland},
  journal={IEEE Transactions on Robotics},
  volume={29},
  number={6},
  pages={1353--1365},
  year={2013},
  publisher={IEEE}
}
@inproceedings{liu2012markov,
  title={A Markov semi-supervised clustering approach and its application in topological map extraction},
  author={Liu, Ming and Colas, Francis and Pomerleau, Fran{\c{c}}ois and Siegwart, Roland},
  booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={4743--4748},
  year={2012},
  organization={IEEE}
}
@article{liu2015incremental,
  title={Incremental topological segmentation for semi-structured environments using discretized GVG},
  author={Liu, Ming and Colas, Francis and Oth, Luc and Siegwart, Roland},
  journal={Autonomous Robots},
  volume={38},
  number={2},
  pages={143--160},
  year={2015},
  publisher={Springer}
}
@inproceedings{muller2005off,
	title = {Off-Road Obstacle Avoidance through End-to-End Learning},
	author = {Urs Muller and Jan Ben and Eric Cosatto and Beat Flepp and Yann L. Cun},
	booktitle = {Advances in Neural Information Processing Systems 18},
	editor = {Y. Weiss and B. Sch\"{o}lkopf and J. C. Platt},
	pages = {739--746},
	year = {2006},
	publisher = {MIT Press},
	url = {http://papers.nips.cc/paper/2847-off-road-obstacle-avoidance-through-end-to-end-learning.pdf}
}
@ARTICLE{giusti2016machine,
  author={
	Giusti, Alessandro and Guzzi, J{\'e}r{\^o}me and Cire{\c{s}}an, Dan C and He, Fang-Lin and Rodr{\'\i}guez, Juan P and Fontana, Flavio and Faessler, Matthias and Forster, Christian and Schmidhuber, J{\"u}rgen and Di Caro, Gianni and Davide Scaramuzza and Luca M. Gambardella},
  journal={IEEE Robotics and Automation Letters},
  title={A Machine Learning Approach to Visual Perception of Forest Trails for Mobile Robots},
  year={2016},
  volume={1},
  number={2},
  pages={661-667},
  keywords={autonomous aerial vehicles;helicopters;image classification;learning (artificial intelligence);microrobots;neural nets;robot vision;machine learning approach;visual perception;forest trails;mobile robots;monocular image;deep-neural network;supervised image classifier;viewing direction;qualitative analysis;quantitative analysis;quadrotor microaerial vehicle control;Cameras;Robot vision systems;Roads;Visual perception;Mobile robots;Image segmentation;Visual-Based Navigation;Aerial Robotics;Machine Learning;Deep Learning;Visual-Based Navigation;Aerial Robotics;Machine Learning;Deep Learning},
  doi={10.1109/LRA.2015.2509024},
  ISSN={2377-3766},
  month={July},
}

@INPROCEEDINGS{choi2018uncertain,
  author={
		Choi, Sungjoon and Lee, Kyungjae and Lim, Sungbin and Oh, Songhwai
	},
  booktitle={2018 IEEE international conference on robotics and automation (ICRA)},
  title={Uncertainty-Aware Learning from Demonstration Using Mixture Density Networks with Sampling-Free Variance Modeling},
  year={2018},
  volume={},
  number={},
  pages={6915-6922},
  keywords={estimation theory;learning (artificial intelligence);learning systems;measurement uncertainty;mobile robots;Monte Carlo methods;sampling methods;uncertainty handling;uncertainty estimation method utilizing;Monte Carlo sampling;robotics applications;autonomous driving;epistemic uncertainties;aleatoric uncertainties;uncertainty acquisition;demonstration method;sampling-free variance modeling;mixture density network;uncertainty-aware learning;Uncertainty;Predictive models;Noise measurement;Data models;Training;Estimation;Measurement uncertainty},
  doi={10.1109/ICRA.2018.8462978},
  ISSN={2577-087X},
  month={May},
}

@article{kahn2017uncertainty,
  title={Uncertainty-aware reinforcement learning for collision avoidance},
  author={Kahn, Gregory and Villaflor, Adam and Pong, Vitchyr and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1702.01182},
  year={2017}
}

@InProceedings{henaff2019model,
  title={Model-Predictive Policy Learning with Uncertainty Regularization for Driving in Dense Traffic},
  author={Mikael Henaff and Alfredo Canziani and Yann LeCun},
  booktitle={International Conference on Learning Representations},
  year={2019},
  url={https://openreview.net/forum?id=HygQBn0cYm},
}

@phdthesis{gal2016uncertainty,
  title={Uncertainty in deep learning},
  author={Gal, Yarin},
  school={University of Cambridge},
  year={2016},
}

@inproceedings{kendall2018multi,
  title={Multi-task learning using uncertainty to weigh losses for scene geometry and semantics},
  author={Kendall, Alex and Gal, Yarin and Cipolla, Roberto},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={7482--7491},
  year={2018}
}


@InProceedings{pan2017virtual,
  title={Virtual to real reinforcement learning for autonomous driving},
  author={Pan, Xinlei and You, Yurong and Wang, Ziyan and Lu, Cewu},
  booktitle={Proceedings of the British Machine Vision Conference ({BMVC})},
  year={2017}
}
@InProceedings{Huang_2018_ECCV,
  author = {Huang, Xun and Liu, Ming-Yu and Belongie, Serge and Kautz, Jan},
  title = {Multimodal Unsupervised Image-to-image Translation},
  booktitle = {The European Conference on Computer Vision (ECCV)},
  month = {September},
  year = {2018}
}

@InProceedings{almahairi2018augmented,
  title = 	 {Augmented {C}ycle{GAN}: Learning Many-to-Many Mappings from Unpaired Data},
  author = 	 {Almahairi, Amjad and Rajeshwar, Sai and Sordoni, Alessandro and Bachman, Philip and Courville, Aaron},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {195--204},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Stockholmsmässan, Stockholm Sweden},
  month = 	 {10--15 Jul},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/almahairi18a/almahairi18a.pdf},
  url = 	 {http://proceedings.mlr.press/v80/almahairi18a.html},
  abstract = 	 {Learning inter-domain mappings from unpaired data can improve performance in structured prediction tasks, such as image segmentation, by reducing the need for paired data. CycleGAN was recently proposed for this problem, but critically assumes the underlying inter-domain mapping is approximately deterministic and one-to-one. This assumption renders the model ineffective for tasks requiring flexible, many-to-many mappings. We propose a new model, called Augmented CycleGAN, which learns many-to-many mappings between domains. We examine Augmented CycleGAN qualitatively and quantitatively on several image datasets.}
}
@inproceedings{mccarthy2004performance,
  title={Performance of optical flow techniques for indoor navigation with a mobile robot},
  author={McCarthy, Chris and Bames, Nick},
  booktitle={2004 IEEE international conference on robotics and automation (ICRA)},
  volume={5},
  pages={5093--5098},
  year={2004},
  organization={IEEE}
}
@inproceedings{lee2018diverse,
  title={Diverse image-to-image translation via disentangled representations},
  author={Lee, Hsin-Ying and Tseng, Hung-Yu and Huang, Jia-Bin and Singh, Maneesh and Yang, Ming-Hsuan},
  booktitle={The European Conference on Computer Vision (ECCV)},
  pages={35--51},
  year={2018}
}
@inproceedings{quigley2009ros,
  title={ROS: an open-source Robot Operating System},
  author={Quigley, Morgan and Conley, Ken and Gerkey, Brian and Faust, Josh and Foote, Tully and Leibs, Jeremy and Wheeler, Rob and Ng, Andrew Y},
  booktitle={ICRA workshop on open source software},
  volume={3},
  number={3.2},
  pages={5},
  year={2009},
  organization={Kobe, Japan}
}
@inproceedings{xie2015model,
  title={Model-based reinforcement learning with parametrized physical models and optimism-driven exploration},
  author={Xie, Chris and Patil, Sachin and Moldovan, Teodor and Levine, Sergey and Abbeel, Pieter},
  booktitle={2016 IEEE international conference on robotics and automation (ICRA)},
  pages={504--511},
  year={2016},
  organization={IEEE}
}
@inproceedings{duan2016benchmarking,
  title={Benchmarking deep reinforcement learning for continuous control},
  author={Duan, Yan and Chen, Xi and Houthooft, Rein and Schulman, John and Abbeel, Pieter},
  booktitle = {Proceedings of the 33rd International Conference on Machine Learning},
  pages={1329--1338},
  year={2016}
}
@TECHREPORT{zhang2018vrsup,
  title={Supplement file of {VR-Goggles} for robots: Real-to-sim domain adaptation for visual control},
  author={Zhang, Jingwei and Tai, Lei and Yun, Peng and Xiong, Yufeng and Liu, Ming and Boedecker, Joschka and Burgard, Wolfram},
  YEAR  =         {2018},
  FILE  =         {https://ram-lab.com/file/tailei/vr\_goggles/supplement.pdf},
  URL   =         {https://ram-lab.com/file/tailei/vr\_goggles/supplement.pdf},
}
@incollection{ng2006autonomous,
  title={Autonomous inverted helicopter flight via reinforcement learning},
  author={Ng, Andrew Y and Coates, Adam and Diel, Mark and Ganapathi, Varun and Schulte, Jamie and Tse, Ben and Berger, Eric and Liang, Eric},
  booktitle={Experimental Robotics IX},
  pages={363--372},
  year={2006},
  publisher={Springer}
}
@article{tai2016survey,
  title={A Survey of Deep Network Solutions for Learning Control in Robotics: From Reinforcement to Imitation},
  author={Tai, Lei and Zhang, Jingwei and Liu, Ming and Boedecker, Joschka and Burgard, Wolfram},
  journal={arXiv preprint arXiv:1612.07139},
  year={2016}
}
@inproceedings{tai2019end,
  author={Tai, Lei and Yun, Peng and Chen, Yuying and Liu, Congcong and Ye, Haoyang and Liu, Ming},
  title={Visual-based Autonomous Driving Deployment from a Stochastic and Uncertainty-aware Perspective},
  booktitle={2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  year={2019}
}
@inproceedings{burgard1997active,
  title={Active mobile robot localization},
  author={Burgard, Wolfram and Fox, Dieter and Thrun, Sebastian},
  booktitle={IJCAI},
  pages={1346--1352},
  year={1997}
}
@inproceedings{singh2018active,
  title={Active Neural Localization},
  author={Devendra Singh Chaplot and Emilio Parisotto and Ruslan Salakhutdinov},
  booktitle={International Conference on Learning Representations},
  year={2018},
  url={https://openreview.net/forum?id=ry6-G_66b},
  }
@article{tai2017autonomous,
  title={Autonomous exploration of mobile robots through deep neural networks},
  author={Tai, Lei and Li, Shaohua and Liu, Ming},
  journal={International Journal of Advanced Robotic Systems},
  volume={14},
  number={4},
  pages={1729881417703571},
  year={2017},
  publisher={SAGE Publications Sage UK: London, England}
}
@article{tai2016mobile,
  title={Mobile robots exploration through cnn-based reinforcement learning},
  author={Tai, Lei and Liu, Ming},
  journal={Robotics and biomimetics},
  volume={3},
  number={1},
  pages={24},
  year={2016},
  publisher={Springer}
}
@article{espeholt2018impala,
  title={Impala: Scalable distributed deep-rl with importance weighted actor-learner architectures},
  author={Espeholt, Lasse and Soyer, Hubert and Munos, Remi and Simonyan, Karen and Mnih, Volodymir and Ward, Tom and Doron, Yotam and Firoiu, Vlad and Harley, Tim and Dunning, Iain and others},
  journal={arXiv preprint arXiv:1802.01561},
  year={2018}
}
@inproceedings{barthmaron2018distributional,
  title={Distributional Policy Gradients},
  author={Gabriel Barth-Maron and Matthew W. Hoffman and David Budden and Will Dabney and Dan Horgan and Dhruva TB and Alistair Muldal and Nicolas Heess and Timothy Lillicrap},
  booktitle={International Conference on Learning Representations},
  year={2018},
  url={https://openreview.net/forum?id=SyZipzbCb},
}
@inproceedings{alahi2016social,
  title={Social lstm: Human trajectory prediction in crowded spaces},
  author={Alahi, Alexandre and Goel, Kratarth and Ramanathan, Vignesh and Robicquet, Alexandre and Fei-Fei, Li and Savarese, Silvio},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={961--971},
  year={2016}
}
@inproceedings{liu2019gaze,
  title={A Gaze Model Improves Autonomous Driving},
  author={Liu, Congcong and Chen, Yuying and Tai, Lei and Ye, Haoyang and Liu, Ming and Shi, Bertram E},
  booktitle={Proceedings of the 2019 ACM Symposium on Eye Tracking Research \& Applications},
  pages={},
  note={to appear},
  year={2019},
  organization={ACM}
}
@article{chen2019gaze,
  title={Gaze Training by Modulated Dropout Improves Imitation Learning},
  author={Chen, Yuying and Liu, Congcong and Tai, Lei and Liu, Ming and Shi, Bertram E},
  journal={arXiv preprint arXiv:1904.08377},
  year={2019}
}
@article{chen2018crowd,
  title={Crowd-Robot Interaction: Crowd-aware Robot Navigation with Attention-based Deep Reinforcement Learning},
  author={Chen, Changan and Liu, Yuejiang and Kreiss, Sven and Alahi, Alexandre},
  journal={arXiv preprint arXiv:1809.08835},
  year={2018}
}
