\chapter{Proposed Direction}
Based on the above investigations over long-term localization\cite{sarlin2019coarse,paton2016bridging} and mapping\cite{qian2022pocd,schmid2022panoptic} algorithms, the proposed directions lie in following three parts. For current map maintenance systems, accurate 6DoF localization is assumed to be solved and provided as a precondition. Therefore, further tests and research on the localization in dynamic scenes are proposed. Regarding the mapping system, multi-experiences localization (MEL)\cite{paton2016bridging} uses multiple traversals information to continuously build topo-metric maps. It proposed a lifelong learning mapping system without considering the large-scale problem, the map size is not scalable over long-term operation. While POCD\cite{qian2022pocd} maintains the map consistent online without considering that the lighting conditions might be changed significantly. Maintenance of multiple maps of the same scene by typical appearance conditions (e.g. day and night, summer and winter) may improve the robustness of long-term navigation.

\section{Localization in Dynamic Scenes}
Accurate localization guarantees strong preliminary conditions for mapping. In dynamic scenes, the localization might be difficult due to the occlusions. Recent works on Simultaneous Localization and Mapping (SLAM) \cite{8593691,xiao2019dynamic,henein2020dynamic} have issued this problem and proposed to remove the dynamic objects via object detection or semantic segmentation algorithms. Excluding the feature points extracted from dynamic objects provides static feature points for visual odometry to track location. It is possible to adopt this kind of idea and integrate it into HLoc \cite{sarlin2019coarse} which achieves state-of-the-art performance in localization under an appearance-changing environment. From another standing point,\cite{grinvald2021tsdf} using TSDFs to generate a dynamic-object aware scene reconstruction with multiple dynamic objects. It can withstand occlusions introduced by object movement, which is a promising scene representation suitable for dynamic scenes. Therefore, localization in a TSDF-based map can be an interesting direction to dig in. Existing works proposing localization in dense scene reconstruction (3D surfel map\cite{9197022}, signed distance field \cite{8968033}) proved the possibility of such an approach. And the last proposed direction is to investigate further research via experience-based navigation. \cite{paton2016bridging}proposed a localization method to localize across different traversals. Further inspired by \cite{yin2022bioslam}, an online learning mechanism can make use of multiple experiences to improve localization performance. MEL could be combined with current data-driven approaches to serve as an optimization strategy for online learning of long-term localization.
\section{Map Update and Management}
POCD\cite{qian2022pocd} and Panoptic Mapping\cite{schmid2022panoptic} show contributions to the maintenance of online map consistency, which serves as an excellent improvement for robot environment interaction tasks (e.g. mobile manipulation). Based on the experiment result demonstrated by MEL\cite{paton2016bridging}, using multiple maps of different environmental conditions makes a significant boost to the localization methods. In the meantime, TSDF-based methods\cite{fehr2017tsdf,grinvald2021tsdf} prove truncated signed distance functions to be an effective map representation under changing environments. Therefore, the construction and maintenance of multiple TSDF-based maps could be a potential research direction. As brought by MEL, the scalability of the map is an open problem. In the MEL system, there is no management over experiences, which means all the repeated traversals are stored, which could lead to the large data stored and the exhaustive search over increasingly larger Spatio-temporal-pose-graph could lead to inefficiency over long-term operation. There are two possible approaches to this scalability issue. One is to use a limited number of experiences, which involve the 
inter-experience evaluation, with designed criteria such as using semantics to guide the metrics over inter-experience changes. An intuitive idea for a cross-season map is to filter out one representative experience for each season. While POCD classifies the environment into dynamic objects, semi-static objects, and static objects, using semantics can be strong prior to potential changes that may appear on the map. However, scene semantic inference remains an open problem since current semantic segmentation and panoptic segmentation algorithms are limited by domain adaptation, generalization, and extensive training data demands. Another direction that remains open is the data structure of the map, there has been a focus in the LiDAR-based SLAM system (e.g. iKD-Tree\cite{cai2021ikd}, Octree\cite{hornung2013octomap}). Similar approaches could be adopted to the visual community with incrementally increased spare feature points as well as potential properties (e.g. semantics, weather, seasons).
\section{Dataset}\label{dataset}
Dataset is essential in order to research long-term visual localization and mapping. Because current popular datasets such as EUROC\cite{burri2016euroc}, TUM\cite{sturm12iros}, and ICL-NUIM\cite{handa:etal:ICRA2014}, mostly focus on localization and mapping within one traversals. The repeated observations are in a short period, which is limited to testing the long-term localization and mapping performance. For VPR, there are Oxford Robocar\cite{RobotCarDatasetIJRR}, NCLT\cite{ncarlevaris-2015a}, and Pittsburgh250k\cite{Torii-PAMI2015}. The main focus is the illumination change and viewpoint change. While VPR datasets provide image sequences over different times of the day or even across seasons, they do not focus on structure changes over time which may happen indoors. TorWICD\cite{qian2022pocd} and RIO\cite{wald2019rio} provides a good example of object level changes under multiple repeated traversals. They lack 3D laser scan data which could be used to achieve accurate pose estimation and 3D scene reconstruction. In order to generate a benchmark for long-term visual localization and mapping, I proposed to use a portable sensor fusion platform (FusionPortable) that could be deployed to a wide range of mobile platforms (e.g. wheel robots, quadruped robots, and hand-held devices). Using the FusionPortable platform, monocular camera, stereo camera, and event camera as well as 3D laser scenario, IMU, GPS, and RTK data could be acquired. With mobile platform quadruped robot, autonomous vehicle, and hand-held device, the dataset could provide cross-platform, long-term, object-level aware data under dynamic and static environments on campus. To get accurate structural change caused by semi-static object movement, we proposed to use high definition image laser scanner (i.e. Leica BLK360 G1) to get the high-resolution 3D reconstruction of the indoor office over a long period.


